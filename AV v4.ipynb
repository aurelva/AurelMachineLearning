{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curriculum: Twitter US Airline Sentiment\n",
    "\n",
    "Steps and tasks:\n",
    "\n",
    "1. Import the libraries, load dataset, the print shape of data, data description. (5 Marks)\n",
    "2. Understand of data columns: (5 Marks)\n",
    "     a. Drop all other columns except “text” and “airline_sentiment”.\n",
    "     b. Check the shape of the data.\n",
    "     c. Print the first 5 rows of data.\n",
    "3. Text pre-processing: Data preparation. (16 Marks)\n",
    "NOTE:- Each text pre-processing step should be mentioned in the notebook separately.\n",
    "     a. Html tag removal.\n",
    "     b. Tokenization.\n",
    "     c. Remove the numbers.\n",
    "     d. Removal of Special Characters and Punctuations.\n",
    "     e. Removal of stopwords\n",
    "     f. Conversion to lowercase.\n",
    "     g. Lemmatize or stemming.\n",
    "     h. Join the words in the list to convert back to text string in the data frame. (So that each row contains the data in text format.)\n",
    "     i. Print the first 5 rows of data after pre-processing.\n",
    "4. Vectorization: (10 Marks)\n",
    "    a. Use CountVectorizer.\n",
    "    b. Use TfidfVectorizer.\n",
    "5. Fit and evaluate the model using both types of vectorization. (6+6 Marks)\n",
    "6. Summarize your understanding of the application of Various Pre-processing and Vectorization \n",
    "     and performance of your model on this dataset. (8 Marks)\n",
    "7.Overall notebook should have:(4 Marks)\n",
    "     a. Well commented code\n",
    "     b. Structure and flow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import and Data Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/aurelienvallier/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/aurelienvallier/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: vaderSentiment in ./opt/anaconda3/lib/python3.8/site-packages (3.3.2)\n",
      "Requirement already satisfied: requests in ./opt/anaconda3/lib/python3.8/site-packages (from vaderSentiment) (2.24.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in ./opt/anaconda3/lib/python3.8/site-packages (from requests->vaderSentiment) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in ./opt/anaconda3/lib/python3.8/site-packages (from requests->vaderSentiment) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in ./opt/anaconda3/lib/python3.8/site-packages (from requests->vaderSentiment) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./opt/anaconda3/lib/python3.8/site-packages (from requests->vaderSentiment) (2021.5.30)\n"
     ]
    }
   ],
   "source": [
    "# Import librairy\n",
    "import numpy as np                                  \n",
    "import pandas as pd                                 \n",
    "import nltk                                         \n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "from nltk.corpus import stopwords, wordnet                 #Stopwords corpus\n",
    "from nltk.stem import PorterStemmer                 # Stemmer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize \n",
    "import re\n",
    "\n",
    "from bs4 import BeautifulSoup                 # Beautiful soup is a parsing library that can use different parsers.\n",
    "\n",
    "from nltk.corpus import stopwords, wordnet    # Stopwords, and wordnet corpus\n",
    "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer          #For Bag of words\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer          #For TF-IDF\n",
    "\n",
    "!pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "data=pd.read_csv('/Users/aurelienvallier/Desktop/AI & Machine Learning/8- Natural Language Processing/Tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  570306133677760513           neutral                        1.0000   \n",
       "1  570301130888122368          positive                        0.3486   \n",
       "2  570301083672813571           neutral                        0.6837   \n",
       "3  570301031407624196          negative                        1.0000   \n",
       "4  570300817074462722          negative                        1.0000   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline  \\\n",
       "0            NaN                        NaN  Virgin America   \n",
       "1            NaN                     0.0000  Virgin America   \n",
       "2            NaN                        NaN  Virgin America   \n",
       "3     Bad Flight                     0.7033  Virgin America   \n",
       "4     Can't Tell                     1.0000  Virgin America   \n",
       "\n",
       "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
       "0                    NaN     cairdin                 NaN              0   \n",
       "1                    NaN    jnardino                 NaN              0   \n",
       "2                    NaN  yvonnalynn                 NaN              0   \n",
       "3                    NaN    jnardino                 NaN              0   \n",
       "4                    NaN    jnardino                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0                @VirginAmerica What @dhepburn said.         NaN   \n",
       "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
       "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
       "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
       "\n",
       "               tweet_created tweet_location               user_timezone  \n",
       "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
       "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
       "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  \n",
       "3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)  \n",
       "4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14640, 15)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of                  tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0      570306133677760513           neutral                        1.0000   \n",
       "1      570301130888122368          positive                        0.3486   \n",
       "2      570301083672813571           neutral                        0.6837   \n",
       "3      570301031407624196          negative                        1.0000   \n",
       "4      570300817074462722          negative                        1.0000   \n",
       "...                   ...               ...                           ...   \n",
       "14635  569587686496825344          positive                        0.3487   \n",
       "14636  569587371693355008          negative                        1.0000   \n",
       "14637  569587242672398336           neutral                        1.0000   \n",
       "14638  569587188687634433          negative                        1.0000   \n",
       "14639  569587140490866689           neutral                        0.6771   \n",
       "\n",
       "               negativereason  negativereason_confidence         airline  \\\n",
       "0                         NaN                        NaN  Virgin America   \n",
       "1                         NaN                     0.0000  Virgin America   \n",
       "2                         NaN                        NaN  Virgin America   \n",
       "3                  Bad Flight                     0.7033  Virgin America   \n",
       "4                  Can't Tell                     1.0000  Virgin America   \n",
       "...                       ...                        ...             ...   \n",
       "14635                     NaN                     0.0000        American   \n",
       "14636  Customer Service Issue                     1.0000        American   \n",
       "14637                     NaN                        NaN        American   \n",
       "14638  Customer Service Issue                     0.6659        American   \n",
       "14639                     NaN                     0.0000        American   \n",
       "\n",
       "      airline_sentiment_gold             name negativereason_gold  \\\n",
       "0                        NaN          cairdin                 NaN   \n",
       "1                        NaN         jnardino                 NaN   \n",
       "2                        NaN       yvonnalynn                 NaN   \n",
       "3                        NaN         jnardino                 NaN   \n",
       "4                        NaN         jnardino                 NaN   \n",
       "...                      ...              ...                 ...   \n",
       "14635                    NaN  KristenReenders                 NaN   \n",
       "14636                    NaN         itsropes                 NaN   \n",
       "14637                    NaN         sanyabun                 NaN   \n",
       "14638                    NaN       SraJackson                 NaN   \n",
       "14639                    NaN        daviddtwu                 NaN   \n",
       "\n",
       "       retweet_count                                               text  \\\n",
       "0                  0                @VirginAmerica What @dhepburn said.   \n",
       "1                  0  @VirginAmerica plus you've added commercials t...   \n",
       "2                  0  @VirginAmerica I didn't today... Must mean I n...   \n",
       "3                  0  @VirginAmerica it's really aggressive to blast...   \n",
       "4                  0  @VirginAmerica and it's a really big bad thing...   \n",
       "...              ...                                                ...   \n",
       "14635              0  @AmericanAir thank you we got on a different f...   \n",
       "14636              0  @AmericanAir leaving over 20 minutes Late Flig...   \n",
       "14637              0  @AmericanAir Please bring American Airlines to...   \n",
       "14638              0  @AmericanAir you have my money, you change my ...   \n",
       "14639              0  @AmericanAir we have 8 ppl so we need 2 know h...   \n",
       "\n",
       "      tweet_coord              tweet_created tweet_location  \\\n",
       "0             NaN  2015-02-24 11:35:52 -0800            NaN   \n",
       "1             NaN  2015-02-24 11:15:59 -0800            NaN   \n",
       "2             NaN  2015-02-24 11:15:48 -0800      Lets Play   \n",
       "3             NaN  2015-02-24 11:15:36 -0800            NaN   \n",
       "4             NaN  2015-02-24 11:14:45 -0800            NaN   \n",
       "...           ...                        ...            ...   \n",
       "14635         NaN  2015-02-22 12:01:01 -0800            NaN   \n",
       "14636         NaN  2015-02-22 11:59:46 -0800          Texas   \n",
       "14637         NaN  2015-02-22 11:59:15 -0800  Nigeria,lagos   \n",
       "14638         NaN  2015-02-22 11:59:02 -0800     New Jersey   \n",
       "14639         NaN  2015-02-22 11:58:51 -0800     dallas, TX   \n",
       "\n",
       "                    user_timezone  \n",
       "0      Eastern Time (US & Canada)  \n",
       "1      Pacific Time (US & Canada)  \n",
       "2      Central Time (US & Canada)  \n",
       "3      Pacific Time (US & Canada)  \n",
       "4      Pacific Time (US & Canada)  \n",
       "...                           ...  \n",
       "14635                         NaN  \n",
       "14636                         NaN  \n",
       "14637                         NaN  \n",
       "14638  Eastern Time (US & Canada)  \n",
       "14639                         NaN  \n",
       "\n",
       "[14640 rows x 15 columns]>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14640 entries, 0 to 14639\n",
      "Data columns (total 15 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   tweet_id                      14640 non-null  int64  \n",
      " 1   airline_sentiment             14640 non-null  object \n",
      " 2   airline_sentiment_confidence  14640 non-null  float64\n",
      " 3   negativereason                9178 non-null   object \n",
      " 4   negativereason_confidence     10522 non-null  float64\n",
      " 5   airline                       14640 non-null  object \n",
      " 6   airline_sentiment_gold        40 non-null     object \n",
      " 7   name                          14640 non-null  object \n",
      " 8   negativereason_gold           32 non-null     object \n",
      " 9   retweet_count                 14640 non-null  int64  \n",
      " 10  text                          14640 non-null  object \n",
      " 11  tweet_coord                   1019 non-null   object \n",
      " 12  tweet_created                 14640 non-null  object \n",
      " 13  tweet_location                9907 non-null   object \n",
      " 14  user_timezone                 9820 non-null   object \n",
      "dtypes: float64(2), int64(2), object(11)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Description conclusion: \n",
    "Data consist of a collection of 14640 tweets classified alongside 15 features, whose datatype is a mixture of integers and objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Understanding of data and dropping of unnecessary columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Since our analysis will be on sentiment analysis of the tweet text, we will drop all columns except Text (which is the content of the tweet) and Airline Sentiment (which is the target variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tweet_id', 'airline_sentiment', 'airline_sentiment_confidence',\n",
       "       'negativereason', 'negativereason_confidence', 'airline',\n",
       "       'airline_sentiment_gold', 'name', 'negativereason_gold',\n",
       "       'retweet_count', 'text', 'tweet_coord', 'tweet_created',\n",
       "       'tweet_location', 'user_timezone'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14635</th>\n",
       "      <td>positive</td>\n",
       "      <td>@AmericanAir thank you we got on a different f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14636</th>\n",
       "      <td>negative</td>\n",
       "      <td>@AmericanAir leaving over 20 minutes Late Flig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14637</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@AmericanAir Please bring American Airlines to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14638</th>\n",
       "      <td>negative</td>\n",
       "      <td>@AmericanAir you have my money, you change my ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14639</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@AmericanAir we have 8 ppl so we need 2 know h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14640 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      airline_sentiment                                               text\n",
       "0               neutral                @VirginAmerica What @dhepburn said.\n",
       "1              positive  @VirginAmerica plus you've added commercials t...\n",
       "2               neutral  @VirginAmerica I didn't today... Must mean I n...\n",
       "3              negative  @VirginAmerica it's really aggressive to blast...\n",
       "4              negative  @VirginAmerica and it's a really big bad thing...\n",
       "...                 ...                                                ...\n",
       "14635          positive  @AmericanAir thank you we got on a different f...\n",
       "14636          negative  @AmericanAir leaving over 20 minutes Late Flig...\n",
       "14637           neutral  @AmericanAir Please bring American Airlines to...\n",
       "14638          negative  @AmericanAir you have my money, you change my ...\n",
       "14639           neutral  @AmericanAir we have 8 ppl so we need 2 know h...\n",
       "\n",
       "[14640 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data= data[[\"airline_sentiment\", \"text\"]]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14640, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the shape of the data. \n",
    "data.shape # Still 14640 rows but now only 2 columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  airline_sentiment  \\\n",
      "0           neutral   \n",
      "1          positive   \n",
      "2           neutral   \n",
      "3          negative   \n",
      "4          negative   \n",
      "\n",
      "                                                                                                                             text  \n",
      "0                                                                                             @VirginAmerica What @dhepburn said.  \n",
      "1                                                        @VirginAmerica plus you've added commercials to the experience... tacky.  \n",
      "2                                                         @VirginAmerica I didn't today... Must mean I need to take another trip!  \n",
      "3  @VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp; they have little recourse  \n",
      "4                                                                         @VirginAmerica and it's a really big bad thing about it  \n"
     ]
    }
   ],
   "source": [
    "#Print the first 5 rows of data.\n",
    "pd.set_option('display.max_colwidth', None # we add this in order to have the see the full content of the tweet\n",
    "datafirst5rows=data.iloc[0:5]\n",
    "print(datafirst5rows)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Text pre-processing: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica plus you've added commercials to the experience... tacky.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I need to take another trip!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp;amp; they have little recourse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing about it</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment  \\\n",
       "0           neutral   \n",
       "1          positive   \n",
       "2           neutral   \n",
       "3          negative   \n",
       "4          negative   \n",
       "\n",
       "                                                                                                                             text  \n",
       "0                                                                                             @VirginAmerica What @dhepburn said.  \n",
       "1                                                        @VirginAmerica plus you've added commercials to the experience... tacky.  \n",
       "2                                                         @VirginAmerica I didn't today... Must mean I need to take another trip!  \n",
       "3  @VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp; they have little recourse  \n",
       "4                                                                         @VirginAmerica and it's a really big bad thing about it  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a. Html tag removal using BeautifulSoup\n",
    "def strip_html(text):\n",
    "    soup = BeautifulSoup(data, \"html.parser\")    # Removing HTML tags\n",
    "    return soup.get_text()\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14640, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shape is unchanged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14640 entries, 0 to 14639\n",
      "Data columns (total 2 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   airline_sentiment  14640 non-null  object\n",
      " 1   text               14640 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 228.9+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>[@, VirginAmerica, What, @, dhepburn, said, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>[@, VirginAmerica, plus, you, 've, added, commercials, to, the, experience, ..., tacky, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>[@, VirginAmerica, I, did, n't, today, ..., Must, mean, I, need, to, take, another, trip, !]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>[@, VirginAmerica, it, 's, really, aggressive, to, blast, obnoxious, ``, entertainment, '', in, your, guests, ', faces, &amp;, amp, ;, they, have, little, recourse]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>[@, VirginAmerica, and, it, 's, a, really, big, bad, thing, about, it]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment  \\\n",
       "0           neutral   \n",
       "1          positive   \n",
       "2           neutral   \n",
       "3          negative   \n",
       "4          negative   \n",
       "\n",
       "                                                                                                                                                               text  \n",
       "0                                                                                                                    [@, VirginAmerica, What, @, dhepburn, said, .]  \n",
       "1                                                                        [@, VirginAmerica, plus, you, 've, added, commercials, to, the, experience, ..., tacky, .]  \n",
       "2                                                                      [@, VirginAmerica, I, did, n't, today, ..., Must, mean, I, need, to, take, another, trip, !]  \n",
       "3  [@, VirginAmerica, it, 's, really, aggressive, to, blast, obnoxious, ``, entertainment, '', in, your, guests, ', faces, &, amp, ;, they, have, little, recourse]  \n",
       "4                                                                                            [@, VirginAmerica, and, it, 's, a, really, big, bad, thing, about, it]  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# b. Tokenization. \n",
    "# We will tokenize the words of whole dataframe using nltk.\n",
    "for i, row in data.iterrows():\n",
    "    text = data.at[i, 'text']\n",
    "    words = nltk.word_tokenize(text)\n",
    "    data.at[i,'text'] = words\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>[ , VirginAmerica, What,  , dhepburn, said,  ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>[ , VirginAmerica, plus, you,  ve, added, commercials, to, the, experience,    , tacky,  ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>[ , VirginAmerica, I, did, n t, today,    , Must, mean, I, need, to, take, another, trip,  ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>[ , VirginAmerica, it,  s, really, aggressive, to, blast, obnoxious,   , entertainment,   , in, your, guests,  , faces,  , amp,  , they, have, little, recourse]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>[ , VirginAmerica, and, it,  s, a, really, big, bad, thing, about, it]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment  \\\n",
       "0           neutral   \n",
       "1          positive   \n",
       "2           neutral   \n",
       "3          negative   \n",
       "4          negative   \n",
       "\n",
       "                                                                                                                                                               text  \n",
       "0                                                                                                                    [ , VirginAmerica, What,  , dhepburn, said,  ]  \n",
       "1                                                                        [ , VirginAmerica, plus, you,  ve, added, commercials, to, the, experience,    , tacky,  ]  \n",
       "2                                                                      [ , VirginAmerica, I, did, n t, today,    , Must, mean, I, need, to, take, another, trip,  ]  \n",
       "3  [ , VirginAmerica, it,  s, really, aggressive, to, blast, obnoxious,   , entertainment,   , in, your, guests,  , faces,  , amp,  , they, have, little, recourse]  \n",
       "4                                                                                            [ , VirginAmerica, and, it,  s, a, really, big, bad, thing, about, it]  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# c. remove special characters. We will use a function to iterate through the entire document.\n",
    "def remove_Special_Characters (words):        \n",
    "    \"\"\"remove_special characters and numbers in list of tokenized words\"\"\"\n",
    "    new_words = [] # Create empty list to store pre-processed words.\n",
    "    for word in words: \n",
    "        new_word= re.sub(\"[^a-zA-Z]\", \" \", word) \n",
    "        new_words.append(new_word) \n",
    "    return new_words\n",
    "def normalize(words):\n",
    "    words = remove_Special_Characters (words)\n",
    "    return words\n",
    "# Normalize over the data\n",
    "for i, row in data.iterrows():\n",
    "    words = data.at[i, 'text']\n",
    "    words = normalize(words)\n",
    "    data.at[i,'text'] = words\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>[ , VirginAmerica, What,  , dhepburn, said,  ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>[ , VirginAmerica, plus, you,  ve, added, commercials, to, the, experience,    , tacky,  ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>[ , VirginAmerica, I, did, n t, today,    , Must, mean, I, need, to, take, another, trip,  ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>[ , VirginAmerica, it,  s, really, aggressive, to, blast, obnoxious,   , entertainment,   , in, your, guests,  , faces,  , amp,  , they, have, little, recourse]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>[ , VirginAmerica, and, it,  s, a, really, big, bad, thing, about, it]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment  \\\n",
       "0           neutral   \n",
       "1          positive   \n",
       "2           neutral   \n",
       "3          negative   \n",
       "4          negative   \n",
       "\n",
       "                                                                                                                                                               text  \n",
       "0                                                                                                                    [ , VirginAmerica, What,  , dhepburn, said,  ]  \n",
       "1                                                                        [ , VirginAmerica, plus, you,  ve, added, commercials, to, the, experience,    , tacky,  ]  \n",
       "2                                                                      [ , VirginAmerica, I, did, n t, today,    , Must, mean, I, need, to, take, another, trip,  ]  \n",
       "3  [ , VirginAmerica, it,  s, really, aggressive, to, blast, obnoxious,   , entertainment,   , in, your, guests,  , faces,  , amp,  , they, have, little, recourse]  \n",
       "4                                                                                            [ , VirginAmerica, and, it,  s, a, really, big, bad, thing, about, it]  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# d. remove numbers. We will use a function to iterate through the entire document.\n",
    "def remove_Numbers (words):        \n",
    "    \"\"\"remove_special characters and numbers in list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words: \n",
    "        new_word= re.sub(r'[0-9]+', '', word)\n",
    "        new_words.append(new_word) \n",
    "    return new_words\n",
    "def normalize(words):\n",
    "    words = remove_Numbers(words)\n",
    "    return words\n",
    "# Normalize over the data\n",
    "for i, row in data.iterrows():\n",
    "    words = data.at[i, 'text']\n",
    "    words = normalize(words)\n",
    "    data.at[i,'text'] = words\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>[ , VirginAmerica, What,  , dhepburn, said,  ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>[ , VirginAmerica, plus, you,  ve, added, commercials, to, the, experience,    , tacky,  ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>[ , VirginAmerica, I, did, n t, today,    , Must, mean, I, need, to, take, another, trip,  ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>[ , VirginAmerica, it,  s, really, aggressive, to, blast, obnoxious,   , entertainment,   , in, your, guests,  , faces,  , amp,  , they, have, little, recourse]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>[ , VirginAmerica, and, it,  s, a, really, big, bad, thing, about, it]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment  \\\n",
       "0           neutral   \n",
       "1          positive   \n",
       "2           neutral   \n",
       "3          negative   \n",
       "4          negative   \n",
       "\n",
       "                                                                                                                                                               text  \n",
       "0                                                                                                                    [ , VirginAmerica, What,  , dhepburn, said,  ]  \n",
       "1                                                                        [ , VirginAmerica, plus, you,  ve, added, commercials, to, the, experience,    , tacky,  ]  \n",
       "2                                                                      [ , VirginAmerica, I, did, n t, today,    , Must, mean, I, need, to, take, another, trip,  ]  \n",
       "3  [ , VirginAmerica, it,  s, really, aggressive, to, blast, obnoxious,   , entertainment,   , in, your, guests,  , faces,  , amp,  , they, have, little, recourse]  \n",
       "4                                                                                            [ , VirginAmerica, and, it,  s, a, really, big, bad, thing, about, it]  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# e. remove punctuations. We will use a function to iterate through the entire document.\n",
    "def remove_punctuation(words):\n",
    "    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n",
    "    new_words = []                       \n",
    "    for word in words:\n",
    "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)    \n",
    "    return new_words\n",
    "def normalize(words):\n",
    "    words = remove_punctuation(words)\n",
    "    return words\n",
    "# Normalize over the data\n",
    "for i, row in data.iterrows():\n",
    "    words = data.at[i, 'text']\n",
    "    words = normalize(words)\n",
    "    data.at[i,'text'] = words\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>[ , VirginAmerica, What,  , dhepburn, said,  ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>[ , VirginAmerica, plus,  ve, added, commercials, experience,    , tacky,  ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>[ , VirginAmerica, I, n t, today,    , Must, mean, I, need, take, another, trip,  ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>[ , VirginAmerica,  s, really, aggressive, blast, obnoxious,   , entertainment,   , guests,  , faces,  , amp,  , little, recourse]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>[ , VirginAmerica,  s, really, big, bad, thing]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment  \\\n",
       "0           neutral   \n",
       "1          positive   \n",
       "2           neutral   \n",
       "3          negative   \n",
       "4          negative   \n",
       "\n",
       "                                                                                                                                 text  \n",
       "0                                                                                      [ , VirginAmerica, What,  , dhepburn, said,  ]  \n",
       "1                                                        [ , VirginAmerica, plus,  ve, added, commercials, experience,    , tacky,  ]  \n",
       "2                                                 [ , VirginAmerica, I, n t, today,    , Must, mean, I, need, take, another, trip,  ]  \n",
       "3  [ , VirginAmerica,  s, really, aggressive, blast, obnoxious,   , entertainment,   , guests,  , faces,  , amp,  , little, recourse]  \n",
       "4                                                                                     [ , VirginAmerica,  s, really, big, bad, thing]  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f. remove stopwords. We will use a function to iterate through the entire document.\n",
    "def remove_stopwords(words):\n",
    "    \"\"\"Remove stop words from list of tokenized words\"\"\"\n",
    "    new_words = []                        \n",
    "    for word in words:\n",
    "        if word not in stopwords.words('english'):\n",
    "            new_words.append(word)        \n",
    "    return new_words\n",
    "def normalize(words):\n",
    "    words = remove_stopwords(words)\n",
    "    return words\n",
    "# Normalize over the data\n",
    "for i, row in data.iterrows():\n",
    "    words = data.at[i, 'text']\n",
    "    words = normalize(words)\n",
    "    data.at[i,'text'] = words\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>[ , virginamerica, what,  , dhepburn, said,  ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>[ , virginamerica, plus,  ve, added, commercials, experience,    , tacky,  ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>[ , virginamerica, i, n t, today,    , must, mean, i, need, take, another, trip,  ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>[ , virginamerica,  s, really, aggressive, blast, obnoxious,   , entertainment,   , guests,  , faces,  , amp,  , little, recourse]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>[ , virginamerica,  s, really, big, bad, thing]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment  \\\n",
       "0           neutral   \n",
       "1          positive   \n",
       "2           neutral   \n",
       "3          negative   \n",
       "4          negative   \n",
       "\n",
       "                                                                                                                                 text  \n",
       "0                                                                                      [ , virginamerica, what,  , dhepburn, said,  ]  \n",
       "1                                                        [ , virginamerica, plus,  ve, added, commercials, experience,    , tacky,  ]  \n",
       "2                                                 [ , virginamerica, i, n t, today,    , must, mean, i, need, take, another, trip,  ]  \n",
       "3  [ , virginamerica,  s, really, aggressive, blast, obnoxious,   , entertainment,   , guests,  , faces,  , amp,  , little, recourse]  \n",
       "4                                                                                     [ , virginamerica,  s, really, big, bad, thing]  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#g. Conversion to lowercase. We will use a function to iterate through the entire document.\n",
    "def to_lowercase(words):\n",
    "    \"\"\"Convert all characters to lowercase from list of tokenized words\"\"\"\n",
    "    new_words = []                        \n",
    "    for word in words:\n",
    "        new_word = word.lower()           # Converting to lowercase\n",
    "        new_words.append(new_word)        # Append processed words to new list.\n",
    "    return new_words\n",
    "def normalize(words):\n",
    "    words = to_lowercase(words)\n",
    "    return words\n",
    "# Normalize over the data\n",
    "for i, row in data.iterrows():\n",
    "    words = data.at[i, 'text']\n",
    "    words = normalize(words)\n",
    "    data.at[i,'text'] = words\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/aurelienvallier/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>[ , virginamerica, what,  , dhepburn, say,  ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>[ , virginamerica, plus,  ve, add, commercials, experience,    , tacky,  ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>[ , virginamerica, i, n t, today,    , must, mean, i, need, take, another, trip,  ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>[ , virginamerica,  s, really, aggressive, blast, obnoxious,   , entertainment,   , guests,  , face,  , amp,  , little, recourse]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>[ , virginamerica,  s, really, big, bad, thing]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment  \\\n",
       "0           neutral   \n",
       "1          positive   \n",
       "2           neutral   \n",
       "3          negative   \n",
       "4          negative   \n",
       "\n",
       "                                                                                                                                text  \n",
       "0                                                                                      [ , virginamerica, what,  , dhepburn, say,  ]  \n",
       "1                                                         [ , virginamerica, plus,  ve, add, commercials, experience,    , tacky,  ]  \n",
       "2                                                [ , virginamerica, i, n t, today,    , must, mean, i, need, take, another, trip,  ]  \n",
       "3  [ , virginamerica,  s, really, aggressive, blast, obnoxious,   , entertainment,   , guests,  , face,  , amp,  , little, recourse]  \n",
       "4                                                                                    [ , virginamerica,  s, really, big, bad, thing]  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# h. lemmatize. We will use a function to iterate through the entire document.\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize_verbs(words):\n",
    "    \"\"\"Lemmatize verbs in list of tokenized words\"\"\"\n",
    "    lemmas = []                           \n",
    "    for word in words:\n",
    "        lemma = lemmatizer.lemmatize(word, pos='v')\n",
    "        lemmas.append(lemma)              \n",
    "    return lemmas\n",
    "def normalize(words):\n",
    "    words = lemmatize_verbs(words)\n",
    "    return words\n",
    "# Normalize over the data\n",
    "for i, row in data.iterrows():\n",
    "    words = data.at[i, 'text']\n",
    "    words = normalize(words)\n",
    "    data.at[i,'text'] = words\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalization. We normalise the functions defined earlier\n",
    "def normalize(words):\n",
    "    words = remove_Special_Characters (words)\n",
    "    words = remove_Numbers (words)\n",
    "    words = to_lowercase(words)\n",
    "    words = remove_punctuation(words)\n",
    "    words = remove_stopwords(words)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate the normalize funtion over whole data.\n",
    "for i, row in data.iterrows():\n",
    "    words = data.at[i, 'text']\n",
    "    words = normalize(words)\n",
    "    data.at[i,'text'] = words\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#h. Join the words in the list to convert back to text string in the data frame. (So that each row contains the data in text format.) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The words were appended already in the function, one after the other.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      airline_sentiment  \\\n",
      "0               neutral   \n",
      "1              positive   \n",
      "2               neutral   \n",
      "3              negative   \n",
      "4              negative   \n",
      "...                 ...   \n",
      "14635          positive   \n",
      "14636          negative   \n",
      "14637           neutral   \n",
      "14638          negative   \n",
      "14639           neutral   \n",
      "\n",
      "                                                                                                                                                      text  \n",
      "0                                                                                                            [ , virginamerica, what,  , dhepburn, say,  ]  \n",
      "1                                                                               [ , virginamerica, plus,  ve, add, commercials, experience,    , tacky,  ]  \n",
      "2                                                                      [ , virginamerica, i, n t, today,    , must, mean, i, need, take, another, trip,  ]  \n",
      "3                        [ , virginamerica,  s, really, aggressive, blast, obnoxious,   , entertainment,   , guests,  , face,  , amp,  , little, recourse]  \n",
      "4                                                                                                          [ , virginamerica,  s, really, big, bad, thing]  \n",
      "...                                                                                                                                                    ...  \n",
      "14635                                                                                          [ , americanair, thank, get, different, flight, chicago,  ]  \n",
      "14636  [ , americanair, leave,   , minutes, late, flight,  , no, warn, communication,   , minutes, late, flight,  , that,  s, call, shitty, customer, svc]  \n",
      "14637                                                                                 [ , americanair, please, bring, american, airlines,  , blackberry  ]  \n",
      "14638                                    [ , americanair, money,  , change, flight,  , n t, answer, phone,  , any, suggestions, i, make, commitment,  ,  ]  \n",
      "14639                              [ , americanair,  , ppl, need,  , know, many, seat, next, flight,  , plz, put, us, standby,  , people, next, flight,  ]  \n",
      "\n",
      "[14640 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# i. Print the first 5 rows of data after pre-processing.\n",
    "data2=str(data) # we convert them into string\n",
    "print(data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Vectorization: (10 Marks) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  a. We start by using CountVectorizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary librairies\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data into test and train\n",
    "X=data['text']\n",
    "Y=data['airline_sentiment'] # this is the target variable\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.30,random_state=1,stratify=Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Converting to array\n",
    "X_train= np.array(X_train)\n",
    "X_test=np.array(X_test)\n",
    "y_train=np.array(y_train)\n",
    "y_test=np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization of CountVectorizer\n",
    "cv= CountVectorizer(max_features=1000) # we chose 1000 as start."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Use TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary librairies\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialization of TfidVectorizer\n",
    "vt= TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Fit and evaluate the model using both types of vectorization. (6+6 Marks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets fit CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use fit_transform() \n",
    "train_data_features_countV = cv.fit_transform ([' '.join(arr) for arr in X_train])\n",
    "#I am using the .join to avoir bug with error message \"list\" object has no attribute lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the random forest...\n",
      "RandomForestClassifier(n_estimators=10, n_jobs=4)\n",
      "0.731655487804878\n"
     ]
    }
   ],
   "source": [
    "# Lets use random forest\n",
    "\n",
    "# Initialize a Random Forest classifier with 10 trees\n",
    "forest = RandomForestClassifier(n_estimators = 10,n_jobs=4) \n",
    "# Fit the forest to the training set, using the text bag of words as \n",
    "# features and the airline_sentiment labels as the response variable\n",
    "print (\"Training the random forest...\")\n",
    "forest = forest.fit( train_data_features_countV, y_train)\n",
    "# random forest performance through cross vaidation \n",
    "print (forest)\n",
    "print (np.mean(cross_val_score(forest,train_data_features_countV,y_train,cv=10)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation Count Vect: The mean cross validation for count vect using random forest is 0.74 which is not bad considering no hypertuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets fit Tfid\n",
    "# Use fit_transform() \n",
    "train_data_features_Tfid= vt.fit_transform ([' '.join(arr) for arr in X_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the random forest...\n",
      "RandomForestClassifier(n_estimators=10, n_jobs=4)\n",
      "0.735851181402439\n"
     ]
    }
   ],
   "source": [
    "# Lets use random forest\n",
    "\n",
    "# Initialize a Random Forest classifier with 10 trees\n",
    "forest = RandomForestClassifier(n_estimators = 10,n_jobs=4) \n",
    "# Fit the forest to the training set, using the text bag of words as \n",
    "# features and the airline_sentiment labels as the response variable\n",
    "print (\"Training the random forest...\")\n",
    "forest = forest.fit( train_data_features_Tfid, y_train)\n",
    "# random forest performance through cross vaidation \n",
    "print (forest)\n",
    "print (np.mean(cross_val_score(forest,train_data_features_Tfid,y_train,cv=10)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation Tfid: The mean cross validation using random forest is 0.74 which is decent considering no tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summarize your understanding of the application of Various Pre-processing and Vectorization and performance of your model on this dataset. (8 Marks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary:\n",
    "- The various pre-processing steps have helped us to go from a dataframe with 15 columns containing various text information into a bag of words which contains cleaned up data for NLP. We have removed the columns which are not relevant for NLP and subsquently removed the punctuations, special characters, numbers etc, all elements which create noise and are not easily intepretable as positive, negative or neutral. The bag of words was then vectorized using 2 different techniques (Count and Tfid). \n",
    "- We havesplit the bag of words into train and test and used a supervised model (random forest algorithm) to train the data. The choice of supervised model was guided by the fact that we the target variable was known to us (\"airline_sentiment\").\n",
    "- The performance of the model using vectorized bag of words was decent. Using minimal tuning, we obtained almost 75% for both the Vectorized Count and Tfid, which indicates that both method of vectorizing bear similar results, which makes sense considering there was only one document.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
